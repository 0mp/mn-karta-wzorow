\section{Metody przestrzeni Kryłowa}

% Definicja iteracji w metodach przestrzeni Kryłowa.
\entry
$k$-ta iteracja:
$x_k\in x_o+K_k$,
gdzie $K_k\coloneqq \set{r_0, Ar_0,\ldots, A^{k-1}r_0}$,
gdzie $r_0=b-Ax_0$;

% TODO: Coś tu jest nie tak.
% Metody oparte na minimalizacji błędu.
\entry
Metody oparte na minimalizacji błędu:
$x_k\in x_0 +K_k$ oraz $\norm{x_k - x^*}_B \forall x\in x_0 + K_k$;

% Metody oparte na minimalizacji residuum.
\entry
Metody oparte na minimalizacji residuum:
$\norm{b-Ax_k}_B \leq \norm{b-Ax}_B \forall x\in x_0 +K_k$, gdzie $B=B^T>0$;

% Metoda gradientów sprzężonych (CG).
\entry
Metoda gradientów sprzężonych (CG):
$A=A^T>0$, $x_k\in x_0 + K_k$ t.,
że $\norm{x_k+x^*}_A\leq \norm{x-x^*}_A \forall x\in x_0 + K_k$,
gdzie $\norm{y}^2_A \coloneqq y^TAy$.
Koszt iteracji, to mnożenie wektora przez $A$, czyli $O(N)$.
W idealnej arytmetyce zbieżne do $x^*$ w $\leq N$ iteracjach.
Po $k$ iteracjach:
$\norm{x_k - x^*}_A\leq 2(\frac{\sqrt{H} - 1}{\sqrt{H} + 1})^k\norm{x_0-x^*}_A$,
gdzie $H=\mathrm{cond}_2(A)$;

% TODO: Wzmianka o GMRES.
